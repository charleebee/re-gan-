{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"h2gSMZOLvmKD","executionInfo":{"status":"ok","timestamp":1724006950254,"user_tz":-60,"elapsed":21001,"user":{"displayName":"Charlee Lazar","userId":"11132711876473849096"}},"outputId":"b0a6bbd1-3a42-4d94-e46e-5859e81ea616","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Step 1: Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Step 2: Set Up Paths\n","import os\n","\n","# Change this to your specific dataset path in Google Drive\n","dataset_dir = '/content/drive/My Drive/path_to_your_dataset'\n","\n","# Example paths (adjust these to match your file structure)\n","json_file_path = os.path.join(dataset_dir, 'mask label', 'example.json')\n","image_path = os.path.join(dataset_dir, 'black hoodies', 'example_image.jpg')\n","output_dir = '/content/features_output'"],"metadata":{"id":"tuQTG76ixVzd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 3: Install Required Libraries\n","!pip install torch torchvision pillow"],"metadata":{"id":"ik6on6avxbLl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 4: Import Libraries\n","import json\n","import os\n","from PIL import Image, ImageDraw\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import numpy as np"],"metadata":{"id":"yro50MGXxe46"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 5: Define Functions for Feature Extraction\n","def load_json(json_file_path):\n","    with open(json_file_path, 'r') as f:\n","        data = json.load(f)\n","    return data\n","\n","def extract_features(json_data, image_path):\n","    image = Image.open(image_path)\n","    features = {}\n","\n","    for shape in json_data['shapes']:\n","        label = shape['label']\n","        points = shape['points']\n","        mask = Image.new('L', (image.width, image.height), 0)\n","        ImageDraw.Draw(mask).polygon(points, outline=1, fill=1)\n","        mask = mask.convert('1')\n","        feature = Image.composite(image, Image.new('RGB', (image.width, image.height)), mask)\n","        features[label] = feature\n","    return features\n","\n","def save_features(features, output_dir):\n","    os.makedirs(output_dir, exist_ok=True)\n","    for label, feature in features.items():\n","        feature.save(os.path.join(output_dir, f\"{label}.png\"))"],"metadata":{"id":"sgsbVegyxiPm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 6: Define DCGAN Architecture\n","class Generator(nn.Module):\n","    def __init__(self, nz, ngf, nc):\n","        super(Generator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, nc, ndf):\n","        super(Discriminator, self).__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)"],"metadata":{"id":"B30ZvaI4xiz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 7: Train the DCGAN\n","def train_dcgan(dataloader, netG, netD, criterion, optimizerG, optimizerD, nz, num_epochs=5):\n","    real_label = 1.\n","    fake_label = 0.\n","\n","    for epoch in range(num_epochs):\n","        for i, data in enumerate(dataloader, 0):\n","            ############################\n","            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","            ###########################\n","            # Train with all-real batch\n","            netD.zero_grad()\n","            real_cpu = data[0].cuda()\n","            b_size = real_cpu.size(0)\n","            label = torch.full((b_size,), real_label, dtype=torch.float, device='cuda')\n","            output = netD(real_cpu).view(-1)\n","            errD_real = criterion(output, label)\n","            errD_real.backward()\n","            D_x = output.mean().item()\n","\n","            # Train with all-fake batch\n","            noise = torch.randn(b_size, nz, 1, 1, device='cuda')\n","            fake = netG(noise)\n","            label.fill_(fake_label)\n","            output = netD(fake.detach()).view(-1)\n","            errD_fake = criterion(output, label)\n","            errD_fake.backward()\n","            D_G_z1 = output.mean().item()\n","            errD = errD_real + errD_fake\n","            optimizerD.step()\n","\n","            ############################\n","            # (2) Update G network: maximize log(D(G(z)))\n","            ###########################\n","            netG.zero_grad()\n","            label.fill_(real_label)\n","            output = netD(fake).view(-1)\n","            errG = criterion(output, label)\n","            errG.backward()\n","            D_G_z2 = output.mean().item()\n","            optimizerG.step()\n","\n","            # Print statistics\n","            if i % 50 == 0:\n","                print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}] Loss_D: {errD.item()} Loss_G: {errG.item()} D(x): {D_x} D(G(z)): {D_G_z1}/{D_G_z2}')"],"metadata":{"id":"x76CaNHOxnnd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 8: Generate New Designs\n","def generate_new_design(netG, nz):\n","    with torch.no_grad():\n","        noise = torch.randn(1, nz, 1, 1, device='cuda')\n","        fake_image = netG(noise).detach().cpu()\n","    return fake_image\n","\n","def combine_features(feature_noise_vectors):\n","    combined_noise = torch.cat(feature_noise_vectors, dim=1)\n","    return combined_noise\n","\n","# Example usage\n","if __name__ == \"__main__\":\n","    # Extract features from a single image\n","    json_data = load_json(json_file_path)\n","    features = extract_features(json_data, image_path)\n","    save_features(features, output_dir)\n","\n","    # DCGAN parameters\n","    nz = 100  # Size of z latent vector (i.e., size of generator input)\n","    ngf = 64  # Size of feature maps in generator\n","    ndf = 64  # Size of feature maps in discriminator\n","    nc = 3    # Number of channels in the training images. For color images, this is 3\n","\n","    # Instantiate the generator and discriminator\n","    netG = Generator(nz, ngf, nc).cuda()\n","    netD = Discriminator(nc, ndf).cuda()\n","\n","    # Loss function and optimizers\n","    criterion = nn.BCELoss()\n","    optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","    optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","    # Load your dataset (assuming it is in a folder of images)\n","    from torchvision import datasets, transforms\n","\n","    dataset = datasets.ImageFolder(root=dataset_dir,\n","                                   transform=transforms.Compose([\n","                                       transforms.Resize(64),\n","                                       transforms.CenterCrop(64),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                                   ]))\n","\n","    dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n","\n","    # Train the DCGAN\n","    train_dcgan(dataloader, netG, netD, criterion, optimizerG, optimizerD, nz)\n","\n","    # Generate a new design\n","    new_design = generate_new_design(netG, nz)\n","    plt.imshow(np.transpose(new_design[0], (1, 2, 0)))\n","    plt.show()\n","\n","    # Example of combining 'sleeve' and 'hood' noise vectors\n","    noise_sleeve = torch.randn(1, nz // 2, 1, 1, device='cuda')\n","    noise_hood = torch.randn(1, nz // 2, 1, 1, device='cuda')\n","    combined_noise = combine_features([noise_sleeve, noise_hood])\n","\n","    # Generate the combined design\n","    combined_design = netG(combined_noise)\n","    plt.imshow(np.transpose(combined_design[0].detach().cpu(), (1, 2, 0)))\n","    plt.show()"],"metadata":{"id":"I5ClN3Lqxwie"},"execution_count":null,"outputs":[]}]}